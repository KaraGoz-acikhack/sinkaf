{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"sinkaf/data/troff-v1.0.tsv\",  sep='\\t')\n",
    "\n",
    "# punctuation table\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "def remove_user_names(s):\n",
    "    return re.sub('@[^\\s]+','',s)\n",
    "\n",
    "def remove_numbers(s):\n",
    "    return re.sub('[0-9]','',s)\n",
    "\n",
    "def remove_punctuation(s):\n",
    "    res = [w.translate(table) for w in s.split()]\n",
    "    return \" \".join(res)\n",
    "\n",
    "def n_stemmer(s, n):\n",
    "    if(n>0):\n",
    "        res = [x[:n] for x in s.split()]\n",
    "        return \" \".join(res)\n",
    "    raise Exception(\"n must be a positive integer!\")\n",
    "\n",
    "def pre_process(s, n=5):\n",
    "    return n_stemmer(remove_punctuation(remove_numbers(remove_user_names(s.lower()))), n)\n",
    "\n",
    "data['text'] = data['text'].apply(lambda x: pre_process(x, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels vector for training\n",
    "# modeli egitmek icin siniflandirmalari olustur\n",
    "data['label_sinkaf'] = data['label'] != 'non'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False    28439\n",
       "True      6845\n",
       "Name: label_sinkaf, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# 6.8K offensive - kufurlu yorum\n",
    "# 28K  non-offensive - kufursuz yorum\n",
    "data['label_sinkaf'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_tr = pd.read_csv(\"https://raw.githubusercontent.com/ahmetax/trstop/master/dosyalar/turkce-stop-words\", header=None)\n",
    "\n",
    "stop_words_tr = stop_words_tr[0].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8379\n"
     ]
    }
   ],
   "source": [
    "# Kufurlu veriyi aza ornekleme\n",
    "# Undersampling non offensive data\n",
    "X_false = data[data['label_sinkaf'] == False].sample(6845)[\"text\"]\n",
    "X_true = data[data['label_sinkaf'] == True][\"text\"]\n",
    "X_undersampled = pd.concat([X_false, X_true])\n",
    "y_undersampled = np.concatenate([np.zeros((6845,1)), np.ones((6845,1))])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_undersampled, y_undersampled)\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=2, max_df=0.99, stop_words=frozenset(stop_words_tr))\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "print(len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train acc:\t0.876\nTest acc:\t0.749\n              precision    recall  f1-score   support\n\n         0.0       0.88      0.88      0.88      5124\n         1.0       0.88      0.88      0.88      5143\n\n    accuracy                           0.88     10267\n   macro avg       0.88      0.88      0.88     10267\nweighted avg       0.88      0.88      0.88     10267\n\n              precision    recall  f1-score   support\n\n         0.0       0.76      0.74      0.75      1721\n         1.0       0.74      0.76      0.75      1702\n\n    accuracy                           0.75      3423\n   macro avg       0.75      0.75      0.75      3423\nweighted avg       0.75      0.75      0.75      3423\n\n"
     ]
    }
   ],
   "source": [
    "#undersampling ile %88 train, %75 test basarisi\n",
    "print(\"Train acc:\\t{0:.3f}\".format(clf.score(X_train, y_train)))\n",
    "print(\"Test acc:\\t{0:.3f}\".format(clf.score(X_test, y_test)))\n",
    "\n",
    "print(classification_report(y_train, clf.predict(X_train)))\n",
    "print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "13266\n"
     ]
    }
   ],
   "source": [
    "# Tum veriyi kullanma\n",
    "X = data['text']\n",
    "y = data['label_sinkaf']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=2, max_df=0.99, stop_words=frozenset(stop_words_tr))\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "print(len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True     21342\n",
       "False    21342\n",
       "Name: label_sinkaf, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# az olan degerlerden veri uretimi\n",
    "smote = SMOTE(sampling_strategy=1)\n",
    "X_train, y_train = smote.fit_sample(X_train, y_train)\n",
    "\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train acc:\t0.713\nTest acc:\t0.806\n              precision    recall  f1-score   support\n\n       False       0.66      0.88      0.75     21342\n        True       0.82      0.55      0.66     21342\n\n    accuracy                           0.71     42684\n   macro avg       0.74      0.71      0.71     42684\nweighted avg       0.74      0.71      0.71     42684\n\n              precision    recall  f1-score   support\n\n       False       0.92      0.84      0.87      7097\n        True       0.50      0.69      0.58      1724\n\n    accuracy                           0.81      8821\n   macro avg       0.71      0.76      0.73      8821\nweighted avg       0.84      0.81      0.82      8821\n\n"
     ]
    }
   ],
   "source": [
    "# Az olan orneklerin oversamplingi basarisiz\n",
    "# BoW ile uretilen vektorler sparse oldugu icin, SMOTE tarzi teknikler\n",
    "# ile veri uretimi basarisiz sonuclanmaktadir\n",
    "print(\"Train acc:\\t{0:.3f}\".format(clf.score(X_train, y_train)))\n",
    "print(\"Test acc:\\t{0:.3f}\".format(clf.score(X_test, y_test)))\n",
    "\n",
    "print(classification_report(y_train, clf.predict(X_train)))\n",
    "print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model olusturulmasi\n",
    "# Aza orneklenen veri kullanilarak model olusturulmasi\n",
    "X_false = data[data['label_sinkaf'] == False].sample(6845)[\"text\"]\n",
    "X_true = data[data['label_sinkaf'] == True][\"text\"]\n",
    "X_undersampled = pd.concat([X_false, X_true])\n",
    "y_undersampled = np.concatenate([np.zeros((6845,1)), np.ones((6845,1))])\n",
    "y_undersampled = y_undersampled != 0 \n",
    "\n",
    "vectorizer = CountVectorizer(min_df=2, max_df=0.99, stop_words=frozenset(stop_words_tr))\n",
    "X_train = vectorizer.fit_transform(X_undersampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train acc:\t0.870\n              precision    recall  f1-score   support\n\n       False       0.87      0.87      0.87      6845\n        True       0.87      0.87      0.87      6845\n\n    accuracy                           0.87     13690\n   macro avg       0.87      0.87      0.87     13690\nweighted avg       0.87      0.87      0.87     13690\n\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_undersampled)\n",
    "\n",
    "print(\"Train acc:\\t{0:.3f}\".format(clf.score(X_train, y_undersampled)))\n",
    "print(classification_report(y_undersampled, clf.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([False,  True,  True,  True, False])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# Offensive? - Kufur mu?\n",
    "\n",
    "test = [\"cok iyi\", \n",
    "        \"bi git\", \n",
    "        \"bi siktir git\", \n",
    "        \"bi defol\",\n",
    "        \"mukemmel bir insansin\"]\n",
    "\n",
    "test_processed = vectorizer.transform([pre_process(sentence, 5) for sentence in test])\n",
    "clf.predict(test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.25272762, 0.74295274, 0.99612049, 0.81632094, 0.46115515])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "clf.predict_proba(test_processed)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['sinkaf/data/clf.joblib']"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "#dump it (higher), dump it (higher!)\n",
    "joblib.dump(vectorizer, \"sinkaf/data/vectorizer.joblib\")\n",
    "joblib.dump(clf, \"sinkaf/data/clf.joblib\")\n"
   ]
  }
 ]
}